{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liner Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Understand first Regression\n",
    "\n",
    "Predictive modelling which investigates the relationship between a _dependent variable and independent variable._<br>\n",
    "Please find below Temperature and iCe Cream sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-b8dfa0bbd2b7>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-b8dfa0bbd2b7>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    df.plot.scatter(x='Temperature',y='Ice Cream Sales')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "url = 'Data/Ice_Cream_Sales_vs_Temperature.csv'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(url,encoding = 'unicode_escape')\n",
    "print(df)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            df.plot.scatter(x='Temperature',y='Ice Cream Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here machine learning is trying to learn.<br>\n",
    "1)\tMachine learning like a brain <br>\n",
    "2)\tMachine Learning will see that, at 11.9 °, number are items are sold is 185  and at 25.1 ° the number of item are sold is 614.<br>\n",
    "3)\tMachine learning internally start preparation formula.<br>\n",
    "4)\tMachine learning is plotting a data between dependent variable and independent variable.<br>\n",
    "5)\tSo that in future if someone asked what will be value on sold ice-cream on temperature at 50°.<br>\n",
    "\n",
    "IS it not same as _Correlation_ ? __No__\n",
    "\n",
    "### Correlation \n",
    "\n",
    "When two sets of data are strongly linked together we say they have a _High Correlation._\n",
    "\n",
    "    Correlation is Positive when the values increase together, and\n",
    "    Correlation is Negative when one value decreases as the other increases\n",
    "    \n",
    "A correlation is assumed to be linear (following a line).\n",
    "![image.png](image/Correlation.png)\n",
    "\n",
    "    1 is a perfect positive correlation\n",
    "    0 is no correlation (the values don't seem linked at all)\n",
    "    -1 is a perfect negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e670c99aea62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTemperature\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ice Cream Sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.corrcoef(df.Temperature , df['Ice Cream Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How To Calculate__\n",
    "\n",
    "_Step 1:_ Find the mean of x, and the mean of y <br>\n",
    "_Step 2:_ Subtract the mean of x from every x value (call them \"a\"), do the same for y\t(call them \"b\") <br>\n",
    "_Step 3:_ Calculate: ab, a2 and b2 for every value <br>\n",
    "_Step 4:_ Sum up ab, sum up a2 and sum up b2 <br>\n",
    "_Step 5:_ Divide the sum of ab by the square root of [(sum of a2) × (sum of b2)] <br>\n",
    "\n",
    "![image.png](image/Correlation_Calculation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Regression analysis, we have to find relation between _one dependent_ and _one or many independent variables._<br>\n",
    "        \n",
    "        Age = 5 + Height * 10 + Weight * 13\n",
    "Here we are establishing a relationship between Height & Weight of a person with his/ Her Age.\n",
    "### Linear Regression \n",
    "\n",
    "THis is liner approach, modelling the releationship between a response( or dependent variable) and or independent variables.\n",
    "“Linear Regression” is a method to predict dependent variable (Y) based on values of independent variables (X). whereas independent variables can have either continuous or categorical values. It can be used for the cases where we want to predict some continuous quantity. E.g., Predicting traffic in a retail store.\n",
    "\n",
    "__ Prerequisites__\n",
    "\n",
    "    Correlation (r) – Explains the relationship between two variables, possible values -1 to +1\n",
    "    Variance (σ2)– Measure of spread in your data\n",
    "    Standard Deviation (σ) – Measure of spread in your data (Square root of Variance)\n",
    "    Normal distribution\n",
    "    Residual (error term) – {Actual value – Predicted value}\n",
    "\n",
    "__Linear Regression Line__\n",
    "\n",
    "While doing linear regression our objective is to fit a line through the distribution which is nearest to most of the points. Hence reducing the distance (error term) of data points from the fitted line.\n",
    "\n",
    "![image.png](image/Linear_Regression.png)\n",
    "\n",
    "For example, in above figure (left) dots represent various data points and line (right) represents an approximate line which can explain the relationship between ‘x’ & ‘y’ axes. Through, linear regression we try to find out such a line. For example, if we have one dependent variable ‘Y’ and one independent variable ‘X’ – relationship between ‘X’ & ‘Y’ can be represented in a form of following equation:\n",
    "\n",
    "Y = Β0 + Β1X\n",
    "\n",
    "Where,\n",
    "\n",
    "        Y = Dependent Variable\n",
    "        X = Independent Variable\n",
    "        Β0 = Constant term a.k.a Intercept\n",
    "        Β1 = Coefficient of relationship between ‘X’ & ‘Y’\n",
    "\n",
    "__Few properties of linear regression line__\n",
    "\n",
    "1) Regression line always passes through mean of independent variable (x) as well as mean of dependent variable (y)<br>\n",
    "2) Regression line minimizes the sum of “Square of Residuals”. That’s why the method of Linear Regression is known as “Ordinary Least Square (OLS).<br>\n",
    "    \n",
    "    Why to reduce “Square of errors” and not just the errors?\n",
    "3) Β1 explains change in Y with a change in X  by one unit. In other words, if we increase the value of ‘X’ by one unit then what will be the change in value of Y\n",
    "\n",
    "    Will correlation coefficient between ‘X’ and ‘Y’ be same as Β1?\n",
    "    \n",
    "    \n",
    "![images.png](image/LinearRegression_line.png)\n",
    "\n",
    "__our mottto is not to get a line of perfect fit but to get line is is best fit which has least amount error.__\n",
    "\n",
    "### Model Evaluation Metrics\n",
    "\n",
    "    RMSE\n",
    "        1) less amount of error that line will be best line.\n",
    "        2) it compares a predicted value and an observed or known value.\n",
    "       Algo: \n",
    "           1) Plotting the data points.\n",
    "           2) Try to fit 1000 lines.\n",
    "           3) Calculate RMSE of 1000 lines.\n",
    "           4) Finally, find a min RMSE Value.\n",
    "    R-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assuption \n",
    "\n",
    "We make a few assumptions when we use linear regression to model the relationship between a response and a predictor. These assumptions are essentially conditions that should be met before we draw inferences regarding the model estimates or before we use a model to make prediction.\n",
    "\n",
    "__Assumption #1:__ Your _dependent variable_ should be measured at the continuous level. Examples of such continuous variables\n",
    "\n",
    "    include height (measured in feet and inches), \n",
    "    temperature (measured in oC), \n",
    "    salary (measured in US dollars), \n",
    "    revision time (measured in hours), \n",
    "    intelligence (measured using IQ score), \n",
    "    reaction time (measured in milliseconds), \n",
    "    test performance (measured from 0 to 100), \n",
    "    sales (measured in number of transactions per month)\n",
    "    \n",
    "    \n",
    "__Assumption #2:__ Your _independent variable_ should be measured at the continuous or categorical level. However, if you have a categorical independent variable.\n",
    "\n",
    "\n",
    "__Assumption #3:__ THere should be liner relationship depedent varaible(response) and independent (predictor) varaibles.\n",
    "\n",
    "__Assumption #4:__ Target value should be _normally distributed_\n",
    "    \n",
    "        if target variable is not normally distributed.\n",
    "            1) log transformation or\n",
    "            2) square root transformation.\n",
    "        Can bring into normal distribution.\n",
    "             \n",
    "\n",
    "__Assumption #5:__ Independent varaible should be correlated. Absence of this phenomenon is know as __multicolllinearity.__\n",
    "        \n",
    "          if __multicolllinearity__ is present, it become diffcult to find out which variable is actually contributing to predict the response variable.\n",
    "          \n",
    "__Assumption #6:__ THe error term must have constant variance. THis phenomenon is know as homoscedasticity. THe presence of non-constant variance is referred to hetroscedasticity. THe error term must be normally distributed.\n",
    "\n",
    "![images.png](image/Assumption.png)\n",
    "\n",
    "\n",
    "__Example :__<br> \n",
    "\tUnderstand the data.<br>\n",
    "\tLoad data<br>\n",
    "\tEDA<br>\n",
    "\n",
    "        o\tDistribution of Feature (We are checking distribution of data)\n",
    "        o\tRelation between Dependent variable and Independent variables.\n",
    "        o\tcorrelation between independent variables, correlation should not exist.\n",
    "        \n",
    "\tIf there are no/less relation <br>\n",
    "\n",
    "        o\tTV is highest correlation with sales, Higher the value, higher is relation 0.78, highly correlated.\n",
    "        o\tIf there is good relation between independent variable (TV and Radio) you might have to remove one of the variable.\n",
    "\tYou can drop the column<br>\n",
    "\tYou can club the column <br>\n",
    "\n",
    "    Very Important \n",
    "    Normalization \n",
    "    Scaling\n",
    "    standardization  \n",
    "\n",
    "If your data is not in distribution, try to bring in normal distribution, whether it’s used Normalization /standardization.\n",
    "If the scale is different, that you have to bring into same scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples \n",
    "\n",
    "__Problem & Dataset__\n",
    "\n",
    "Our objective in this problem will be to train a model that accurately predicts the profits of a food truck.\n",
    "The first column in our dataset file contains city populations and the second column contains food truck profits in each city, both in 10,000s. Here are the first few training examples:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt('data/food_truck_data.txt', delimiter=\",\")\n",
    "x = data[:, 0] # city populations\n",
    "y = data[:, 1] # food truck profits\n",
    "'''Both x and y are one dimensional arrays, because we have one feature (population) and one target variable (profit) in this problem. Therefore we can conveniently visualize our dataset using a scatter plot:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, marker=\"x\", c=\"red\")\n",
    "plt.title(\"Food Truck Dataset\", fontsize=16)\n",
    "plt.xlabel(\"City Population in 10,000s\", fontsize=14)\n",
    "plt.ylabel(\"Food Truck Profit in 10,000s\", fontsize=14)\n",
    "plt.axis([4, 25, -5, 25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hypothesis Function__\n",
    "Now we need to come up with a straight line which accurately represents the relationship between population and profit. This is called the hypothesis function and it’s formulated as\n",
    "\n",
    "\\begin{equation}\n",
    "hθ(x)=θ^Tx=\\mathtt{θ}_0 + \\mathtt{θ}_1\\mathtt{x}_1+\\mathtt{θ}_2\\mathtt{x}_2+…+\\mathtt{θ}_n\\mathtt{x}_n \n",
    "\\end{equation}\n",
    "\n",
    "where x corresponds to the feature matrix and θ corresponds to the vector of model parameters.\n",
    "Since we have a single feature $\\mathtt{x}_1$, we’ll only have two model parameters $\\mathtt{θ}_0$ and $\\mathtt{θ}_1$ in our hypothesis function:\n",
    "$$ \\mathtt{h}_θ(x)=θ^Tx=\\mathtt{θ}_0 + \\mathtt{θ}_1\\mathtt{x}_1 $$\n",
    "\n",
    "As you may have noticed, the number of model parameters is equal to the number of features plus 1. That’s because each feature is weighted by a parameter to control its impact on the hypothesis hθ(x). There is also an independent parameter θ0 called the intercept term, which defines the point where the hypothesis function intercepts the y-axis as demonstrated below:\n",
    "\n",
    "The predictions of a hypothesis function can easily be evaluated in Python by computing the cross product of x and θT. At the moment we have our x and y vectors but we don’t have our model parameters yet. So let’s create those as well and initialize them with zeros:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(2)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we have to make sure that the matrix dimensions of x and $\\mathtt{θ}_T$ are compatible with each other for cross product. Currently x has 1 column but $\\mathtt{θ}_T$ has 2 rows. The dimensions don’t match because of the additional intercept term $\\mathtt{θ}_0$.\n",
    "\n",
    "We can solve this issue by prepending a column to x and set it to all ones. This is essentially equivalent to creating a new feature $\\mathtt{x}_0$=1. This extra column won’t affect the hypothesis whatsoever because $\\mathtt{θ}_0$ is going to be multiplied by 1 in the cross product.\n",
    "\n",
    "Let’s create a new variable X to store the extended x matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones(shape=(len(x), 2))\n",
    "X[:, 1] = x\n",
    "'''Finally, we can compute the predictions of our hypothesis as follows:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X @ theta\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Of course, the predictions are currently all zeros because we haven’t trained our model yet.__\n",
    "#### Cost Function\n",
    "\n",
    "The objective in training a linear regression model is to minimize a cost function, which measures the difference between actual y values in the training sample and predictions made by the hypothesis function $\\mathtt{h}_θ(x)$.\n",
    "\n",
    "Such a cost function can be formulated as;\n",
    "\n",
    "$$j(θ) =\\frac{1}{(2m)} \\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2$$\n",
    "\n",
    "where m is the number of training examples.\n",
    "\n",
    "This function is otherwise called the \"Squared error function\", or \"Mean squared error\". The mean is halved $\\left(\\frac{1}{2}\\right)$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $\\frac{1}{2} $\t  term. \n",
    "\n",
    "\n",
    "We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.\n",
    "\n",
    "\n",
    "![image](image/costfunction.png)\n",
    "\n",
    "_Recap._ We're closing this problem as, find me the values of theta zero and theta one so that the average, the 1 over the 2m, times the sum of square errors between my predictions on the training set minus the actual values of the houses on the training set is minimized. So this is going to be my overall objective function for linear regression.\n",
    "\n",
    "\n",
    "$$J(\\theta_0, \\theta_1) = \\dfrac {1}{2m} \\displaystyle \\sum _{i=1}^m \\left ( \\hat{y}_{i}- y_{i} \\right)^2 = \\dfrac {1}{2m} \\displaystyle \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2$$\n",
    "\n",
    "#### Cost Function - Intuition I\n",
    "\n",
    "![image](image/CostIntuition.png)\n",
    "\n",
    "It turns out that two key functions we want to understand. The first is the hypothesis function, and the second is a cost function. So, notice that the hypothesis, right, H of X. For a face value of theta one, this is a function of X. So the hypothesis is a function of, what is the size of the house X. In contrast, the cost function, J, that's a function of the parameter, theta one, which controls the slope of the straight line. Let's plot these functions and try to understand them both better. Let's start with the hypothesis. On the left, let's say here's my training set with three points at (1, 1), (2, 2), and (3, 3). Let's pick a value theta one, so when theta one equals one, and if that's my choice for theta one, then my hypothesis is going to look like this straight line over here. And I'm gonna point out, when I'm plotting my hypothesis function. X-axis, my horizontal axis is labeled X, is labeled you know, size of the house over here. Now, of temporary, set theta one equals one, what I want to do is figure out what is j of theta one, when theta one equals one. So let's go ahead and compute what the cost function has for. You'll devalue one. Well, as usual, my cost function is defined as follows, right? Some from, some of 'em are training sets of this usual squared error term. And, this is therefore equal to. And this. Of theta one x I minus y I and if you simplify this turns out to be. That. Zero Squared to zero squared to zero squared which is of course, just equal to zero. Now, inside the cost function. It turns out each of these terms here is equal to zero. Because for the specific training set I have or my 3 training examples are (1, 1), (2, 2), (3,3). If theta one is equal to one. Then h of x. H of x i. Is equal to y I exactly, let me write this better. Right? And so, h of x minus y, each of these terms is equal to zero, which is why I find that j of one is equal to zero. So, we now know that j of one Is equal to zero. Let's plot that. What I'm gonna do on the right is plot my cost function j. And notice, because my cost function is a function of my parameter theta one, when I plot my cost function, the horizontal axis is now labeled with theta one. So I have j of one zero zero so let's go ahead and plot that. End up with. An X over there. Now lets look at some other examples. Theta-1 can take on a range of different values. Right? So theta-1 can take on the negative values, zero, positive values. So what if theta-1 is equal to 0.5. What happens then? Let's go ahead and plot that. I'm now going to set theta-1 equals 0.5, and in that case my hypothesis now looks like this. As a line with slope equals to 0.5, and, lets compute J, of 0.5. So that is going to be one over 2M of, my usual cost function. It turns out that the cost function is going to be the sum of square values of the height of this line. Plus the sum of square of the height of that line, plus the sum of square of the height of that line, right? ?Cause just this vertical distance, that's the difference between, you know, Y. I. and the predicted value, H of XI, right? So the first example is going to be 0.5 minus one squared. Because my hypothesis predicted 0.5. Whereas, the actual value was one. For my second example, I get, one minus two squared, because my hypothesis predicted one, but the actual housing price was two. And then finally, plus. 1.5 minus three squared. And so that's equal to one over two times three. Because, M when trading set size, right, have three training examples. In that, that's times simplifying for the parentheses it's 3.5. So that's 3.5 over six which is about 0.68. So now we know that j of 0.5 is about 0.68.[Should be 0.58] Lets go and plot that. Oh excuse me, math error, it's actually 0.58. So we plot that which is maybe about over there. Okay? Now, let's do one more. How about if theta one is equal to zero, what is J of zero equal to? It turns out that if theta one is equal to zero, then H of X is just equal to, you know, this flat line, right, that just goes horizontally like this. And so, measuring the errors. We have that J of zero is equal to one over two M, times one squared plus two squared plus three squared, which is, One six times fourteen which is about 2.3. So let's go ahead and plot as well. So it ends up with a value around 2.3 and of course we can keep on doing this for other values of theta one. It turns out that you can have you know negative values of theta one as well so if theta one is negative then h of x would be equal to say minus 0.5 times x then theta one is minus 0.5 and so that corresponds to a hypothesis with a slope of negative 0.5. And you can actually keep on computing these errors. This turns out to be, you know, for 0.5, it turns out to have really high error. It works out to be something, like, 5.25. And so on, and the different values of theta one, you can compute these things, right? And it turns out that you, your computed range of values, you get something like that. And by computing the range of values, you can actually slowly create out. What does function J of Theta say and that's what J of Theta is. To recap, for each value of theta one, right? Each value of theta one corresponds to a different hypothesis, or to a different straight line fit on the left. And for each value of theta one, we could then derive a different value of j of theta one. And for example, you know, theta one=1, corresponded to this straight line straight through the data. Whereas theta one=0.5. And this point shown in magenta corresponded to maybe that line, and theta one=zero which is shown in blue that corresponds to this horizontal line. Right, so for each value of theta one we wound up with a different value of J of theta one and we could then use this to trace out this plot on the right. Now you remember, the optimization objective for our learning algorithm is we want to choose the value of theta one. __That minimizes J of theta one. Right?__ This was our objective function for the linear regression. Well, looking at this curve, the value that minimizes j of theta one is, you know, __theta one equals to one.__ And low and behold, that is indeed the __best possible straight line fit through our data,__ by setting theta one equals one. And just, for this particular training set, we actually end up fitting it perfectly. And that's why minimizing j of theta one corresponds to finding a straight line that fits the data well. \n",
    "\n",
    "__Thus as a goal, we should try to minimize the cost function. In this case, \\theta_1 = 1θ __\n",
    "\n",
    "#### Cost Function - Intuition II\n",
    "\n",
    "Reference : https://www.coursera.org/learn/machine-learning/supplement/9SEeJ/cost-function-intuition-ii\n",
    "Here’s its Python version:\n",
    "\n",
    "        def cost(theta, X, y):\n",
    "            predictions = X @ theta\n",
    "            squared_errors = np.square(predictions - y)\n",
    "            return np.sum(squared_errors) / (2 * len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    predictions = X @ theta\n",
    "    squared_errors = np.square(predictions - y)\n",
    "    return np.sum(squared_errors) / (2 * len(y))\n",
    "\n",
    "'''Now let’s take a look at the cost of our initial untrained model:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The initial cost is:', cost(theta, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent Algorithm\n",
    "https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent\n",
    "\n",
    "algorithm called gradient descent for minimizing the cost function. It turns out gradient descent is a more general algorithm, and is used not only in linear regression. It's actually used all over the place in machine learning. \n",
    "\n",
    "\n",
    "So we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.\n",
    "\n",
    "Imagine that we graph our hypothesis function based on its fields $\\theta_0$  and  $\\theta_1$  (actually we are graphing the cost function as a function of the parameter estimates). We are not graphing x and y itself, but the parameter range of our hypothesis function and the cost resulting from selecting a particular set of parameters.\n",
    "\n",
    "We put $\\theta_0$  on the x axis and  $\\theta_1$  on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters. The graph below depicts such a setup.\n",
    "\n",
    "![image](image/gradient-descent.png)\n",
    "We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the minimum. The red arrows show the minimum points in the graph.\n",
    "\n",
    "The way we do this is by taking the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter α, which is called the learning rate.\n",
    "\n",
    "For example, the distance between each 'star' in the graph above represents a step determined by our parameter α. A smaller α would result in a smaller step and a larger α results in a larger step. The direction in which the step is taken is determined by the partial derivative of $J(\\theta_0,\\theta_1)$. Depending on where one starts on the graph, one could end up at different points. The image above shows us two different starting points that end up in two different places.\n",
    "\n",
    "The gradient descent algorithm is:\n",
    "\n",
    "repeat until convergence:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1)$$\n",
    "\n",
    "where\n",
    "\n",
    "j=0,1 represents the feature index number.\n",
    "\n",
    "there's lot of details in this equation so let me unpack some of it.<br>\n",
    "\n",
    "    1)  First, this notation here, :=, gonna use := to denote assignment, so it's the assignment operator. So briefly, if I write a := b, what this means is, it means in a computer, this means take the value in b and use it overwrite whatever value is a. So this means set a to be equal to the value of b, which is assignment. And I can also do a := a + 1. This means take a and increase its value by one. Whereas in contrast, if I use the equal sign and I write a equals b, then this is a truth assertion.\n",
    "\n",
    "    2) So if I write a equals b, then I'll asserting that the value of a equals to the value of b, right? So the left hand side, that's the computer operation, where we set the value of a to a new value. The right hand side, this is asserting, I'm just making a claim that the values of a and b are the same, and so whereas you can write a := a + 1, that means increment a by 1, hopefully I won't ever write a = a + 1 because that's just wrong. a and a + 1 can never be equal to the same values.\n",
    "\n",
    "    3) This alpha here is a number that is called the learning rate.And what alpha does is it basically controls how big a step we take downhill with creating descent. So if alpha is very large, then that corresponds to a very aggressive gradient descent procedure where we're trying take huge steps downhill and if alpha is very small, then we're taking little, little baby steps downhill\n",
    "    \n",
    "    4) this term here, that's a derivative term.\n",
    "\n",
    "At each iteration j, one should simultaneously update the parameters $\\theta_1, \\theta_2,...,\\theta_n $updating a specific parameter prior to calculating another one on the $j^{(th)}$ iteration would yield to a wrong implementation.\n",
    "\n",
    "Since our hypothesis is based on the model parameters θ, we must somehow adjust them to minimize our cost function J(θ). This is where the gradient descent algorithm comes into play. It’s an optimization algorithm which can be used in minimizing differentiable functions. Luckily our cost function J(θ) happens to be a differentiable one.\n",
    "\n",
    "\n",
    "\n",
    "#### Gradient Descent Intuition\n",
    "\n",
    "let's take the tangent to that point, like that straight line, that red line, is just touching this function, and let's look at the slope of this red line. That's what the derivative is, it's saying what's the slope of the line that is just tangent to the function. Okay, the slope of a line is just this height divided by this horizontal thing. Now, this line has a positive slope, so it has a positive derivative. And so my update to theta is going to be theta 1, it gets updated as theta 1, minus alpha times some positive number.\n",
    "\n",
    "\n",
    "Alpha the the learning, is always a positive number. And, so we're going to take theta one is updated as theta one minus something. So I'm gonna end up moving theta one to the left. I'm gonna decrease theta one, and we can see this is the right thing to do cuz I actually wanna head in this direction. You know, to get me closer to the minimum over there.\n",
    "\n",
    "\n",
    "![image](image/gradient-Intuition.png)\n",
    "\n",
    "It turns out the local optimum, your derivative will be equal to zero. So for that slope, that tangent point, so the slope of this line will be equal to zero and thus this derivative term is equal to zero. And so your gradient descent update, you have theta one cuz I updated this theta one minus alpha times zero. And so what this means is that if you're already at the local optimum it leaves theta 1 unchanged cause its updates as theta 1 equals theta 1. So if your parameters are already at a local minimum one step with gradient descent does absolutely nothing it doesn't your parameter which is what you want because it keeps your solution at the local optimum.\n",
    "\n",
    "\n",
    "__Book Defination__ \n",
    "So here’s how the gradient descent algorithm works in a nutshell:\n",
    "\n",
    "In each iteration, it takes a small step in the opposite gradient direction of J(θ). This makes the model parameters θ gradually come closer to the optimal values. This process is repeated until eventually the minimum cost is achieved.\n",
    "\n",
    "More formally, gradient descent performs the following update in each iteration\n",
    "\n",
    "$$j(θ) := θ_j -α\\frac{1}{(m)} \\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^i$$\n",
    "\n",
    "The α term here is called the learning rate. It allows us to control the step size to update θ in each iteration. Choosing a too large learning rate may prevent us from converging to a minimum cost, whereas choosing a too small learning rate may significantly slow down the algorithm.\n",
    "\n",
    "\n",
    "#### Gradient Descent For Linear Regression\n",
    "What we're going to do is apply gradient descent to minimize our squared error cost function. \n",
    "\n",
    "When specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived. We can substitute our actual cost function and our actual hypothesis function and modify the equation to :\n",
    "\n",
    "\\begin{align*} \\text{repeat until convergence: } \\lbrace & \\newline \\theta_0 := & \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}(h_\\theta(x_{i}) - y_{i}) \\newline \\theta_1 := & \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}\\left((h_\\theta(x_{i}) - y_{i}) x_{i}\\right) \\newline \\rbrace& \\end{align*}\n",
    "\n",
    "where m is the size of the training set, $\\theta_0$ a constant that will be changing simultaneously with $\\theta_1$ and $x_{i}, y_{i}$ are values of the given training set (data).\n",
    "\n",
    "Note that we have separated out the two cases for $\\theta_j$  into separate equations for $\\theta_0$ and $\\theta_1$ and that for $\\theta_1$ we are multiplying $x_{i}$  at the end due to the derivative. The following is a derivation of $∂/{∂θ_j} J(θ)$ for a single example :\n",
    "\n",
    "\n",
    "https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression \n",
    "\n",
    "\n",
    "Here’s a generic implementation of the gradient descent algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha, num_iters):\n",
    "    num_features = X.shape[1]               \n",
    "    theta = np.zeros(num_features)          # initialize model parameters\n",
    "    for n in range(num_iters):\n",
    "        predictions = X @ theta             # compute predictions based on the current hypothesis\n",
    "        errors = predictions - y\n",
    "        gradient = X.transpose() @ errors\n",
    "        theta -= alpha * gradient / len(y)  # update model parameters\n",
    "    return theta  \n",
    "\n",
    "'''Now let’s use this function to train our model and plot the hypothesis function:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = gradient_descent(X, y, 0.02, 600)   # run GD for 600 iterations with learning rate = 0.02\n",
    "predictions = X @ theta                     # predictions made by the optimized model\n",
    "ax.plot(X[:, 1], predictions, linewidth=2)  # plot the hypothesis on top of the training data\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "Our linear fit looks pretty good, right? The algorithm must have successfully optimized our model.\n",
    "\n",
    "Well, to be honest, it’s been fairly easy to visualize the hypothesis because there’s only one feature in this problem.\n",
    "\n",
    "But what if we had multiple features? Then it wouldn’t be possible to simply plot the hypothesis to see whether the algorithm has worked as intended or not.\n",
    "\n",
    "Fortunately, there’s a simple way to debug the gradient descent algorithm irrespective of the number of features:\n",
    "\n",
    "1) Modify the gradient descent function to make it record the cost at the end of each iteration.<br>\n",
    "2) Plot the cost history after the gradient descent has finished.<br>\n",
    "3) Pat yourself on the back if you see that the cost has monotonically decreased over time.<br>\n",
    "\n",
    "Here’s the modified version of our gradient descent function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha, num_iters):\n",
    "    cost_history = np.zeros(num_iters)          # create a vector to store the cost history\n",
    "    num_features = X.shape[1]               \n",
    "    theta = np.zeros(num_features)\n",
    "    for n in range(num_iters):\n",
    "        predictions = X @ theta\n",
    "        errors = predictions - y\n",
    "        gradient = X.transpose() @ errors\n",
    "        theta -= alpha * gradient / len(y)\n",
    "        cost_history[n] = cost(theta, X, y)     # compute and record the cost\n",
    "    return theta, cost_history                  # return optimized parameters and cost history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s try learning rates 0.01, 0.015, 0.02 and plot the cost history for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num_iters = 1200\n",
    "learning_rates = [0.01, 0.015, 0.02]\n",
    "for lr in learning_rates:\n",
    "    _, cost_history = gradient_descent(X, y, lr, num_iters)\n",
    "    plt.plot(cost_history, linewidth=2)\n",
    "plt.title(\"Gradient descent with different learning rates\", fontsize=16)\n",
    "plt.xlabel(\"number of iterations\", fontsize=14)\n",
    "plt.ylabel(\"cost\", fontsize=14)\n",
    "plt.legend(list(map(str, learning_rates)))\n",
    "plt.axis([0, num_iters, 4, 6])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the gradient descent algorithm worked correctly for these particular learning rates. Notice that it takes more iterations to minimize the cost as the learning rate decreases.\n",
    "\n",
    "Now let’s try a larger learning rate and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.025\n",
    "num_iters = 50\n",
    "_, cost_history = gradient_descent(X, y, learning_rate, num_iters)\n",
    "plt.plot(cost_history, linewidth=2)\n",
    "plt.title(\"Gradient descent with learning rate = \" + str(learning_rate), fontsize=16)\n",
    "plt.xlabel(\"number of iterations\", fontsize=14)\n",
    "plt.ylabel(\"cost\", fontsize=14)\n",
    "plt.axis([0, num_iters, 0, 6000])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn’t look good… That’s what happens when the learning rate is too large. Even though the gradient descent algorithm takes steps in the correct direction, these steps are so huge that it’s going to overshoot the target and the cost diverges from the minimum value instead of converging to it.\n",
    "\n",
    "Right now we can safely set the learning rate to 0.02, because it allows us to minimize the cost and it requires relatively fewer iterations to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Now that we’ve learned how to train our model, we can finally predict the food truck profit for a particular city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, _ = gradient_descent(X, y, 0.02, 600)    # train the model\n",
    "test_example = np.array([1, 7])                 # pick a city with 70,000 population as a test example\n",
    "prediction = test_example @ theta               # use the trained model to make a prediction\n",
    "print('For population = 70,000, we predict a profit of $', prediction * 10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Features (multivariate linear regression)\n",
    "\n",
    "Linear regression with multiple variables is also known as \"multivariate linear regression\".\n",
    "\n",
    "We now introduce notation for equations where we can have any number of input variables.\n",
    "\n",
    "\\begin{align*}x_j^{(i)} &= \\text{value of feature } j \\text{ in the }i^{th}\\text{ training example} \\newline x^{(i)}& = \\text{the input (features) of the }i^{th}\\text{ training example} \\newline m &= \\text{the number of training examples} \\newline n &= \\text{the number of features} \\end{align*}\n",
    "\n",
    "The multivariable form of the hypothesis function accommodating these multiple features is as follows:\n",
    "\n",
    "$h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n$\n",
    "\n",
    "In order to develop intuition about this function, we can think about $\\theta_0$ as the basic price of a house, $\\theta_1$ as the price per square meter, $\\theta_2$ as the price per floor, etc. $x_1$ will be the number of square meters in the house, $x_2$ the number of floors, etc.\n",
    "\n",
    "# Gradient Descent For Multiple Variables\n",
    "Gradient Descent for Multiple Variables\n",
    "The gradient descent equation itself is generally the same form; we just have to repeat it for our 'n' features:\n",
    "\n",
    "\\begin{align*} & \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_0^{(i)}\\newline \\; & \\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_1^{(i)} \\newline \\; & \\theta_2 := \\theta_2 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_2^{(i)} \\newline & \\cdots \\newline \\rbrace \\end{align*}\n",
    "\n",
    "In other words:\n",
    "\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\; & \\text{for j := 0...n}\\newline \\rbrace\\end{align*}\n",
    "\n",
    "## Gradient Descent in Practice I - Feature Scaling\n",
    "\n",
    "We can speed up gradient descent by having each of our input values in roughly the same range. This is because θ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.\n",
    "\n",
    "The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally:\n",
    "\n",
    "−1 ≤ $x_{(i)} $≤ 1\n",
    "\n",
    "or\n",
    "\n",
    "−0.5 ≤ $x_{(i)} $ ≤ 0.5\n",
    "\n",
    "These aren't exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.\n",
    "\n",
    "Two techniques to help with this are __feature scaling and mean normalization.__ Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. To implement both of these techniques, adjust your input values as shown in this formula:\n",
    "\n",
    "\n",
    "$$ x_i := \\dfrac{x_i-μ_i}{s_i}$$\n",
    "\n",
    "Where μi is the average of all the values for feature (i) and $s_i$ is the range of values (max - min), or $s_i$ is the standard deviation.\n",
    "\n",
    "Note that dividing by the range, or dividing by the standard deviation, give different results. The quizzes in this course use range - the programming exercises use standard deviation.\n",
    "\n",
    "For example, if $ x_i$ represents housing prices with a range of 100 to 2000 and a mean value of 1000, then,$ x_i := \\dfrac{price-1000}{1900}$\n",
    "\n",
    "## Gradient Descent in Practice II - Learning Rate\n",
    "\n",
    "Debugging gradient descent. Make a plot with number of iterations on the x-axis. Now plot the cost function, J(θ) over the number of iterations of gradient descent. If J(θ) ever increases, then you probably need to decrease α.\n",
    "\n",
    "Automatic convergence test. Declare convergence if J(θ) decreases by less than E in one iteration, where E is some small value such as $10^−3$. However in practice it's difficult to choose this threshold value.\n",
    "\n",
    "![image](image/Learning Rate.png)\n",
    "\n",
    "It has been proven that if learning rate α is sufficiently small, then J(θ) will decrease on every iteration.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "    If α is too small: slow convergence.\n",
    "    If α is too large: ￼may not decrease on every iteration and thus may not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Polynomial Regression\n",
    "\n",
    "Our hypothesis function need not be linear (a straight line) if that does not fit the data well.\n",
    "\n",
    "We can change the behavior or curve of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).\n",
    "\n",
    "For example, if our hypothesis function is $h_\\theta(x) = \\theta_0 + \\theta_1 x_1 $ then we can create additional features based on $x_1$ to get the quadratic function $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2$  or the cubic function $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3 $\n",
    "\n",
    "In the cubic version, we have created new features $x_2$ and $x_3$ where $x_2 = x_1^2 $ and $x_3 = x_1^3$ \n",
    "To make it a square root function, we could do: $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 \\sqrt{x_1}$\n",
    "\n",
    "One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important.\n",
    "\n",
    "eg. if $x_1 $ has range 1 - 1000 then range of $ x_1^2 $ becomes 1 - 1000000 and that of $ x_1^3$  becomes 1 - 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
