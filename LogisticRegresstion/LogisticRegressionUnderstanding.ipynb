{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's understand first __Classfication__ : \n",
    "\n",
    "A classification problem is when the output variable is a _category_, such as “red” or “blue” or “disease” and “no disease”. A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes.\n",
    "\n",
    "__For example__:<br>\n",
    "1) when filtering emails “spam” or “not spam”<br>\n",
    "2) when looking at transaction data, “fraudulent”, or “authorized”<br>\n",
    "\n",
    "In short Classification either predicts categorical class labels or classifies data (construct a model) based on the training set and the values (class labels) in classifying attributes and uses it in classifying new data.\n",
    "\n",
    "Here we have the types of classification algorithms in Machine Learning:\n",
    "\n",
    "- Linear Classifiers: Logistic Regression, Naive Bayes Classifier\n",
    "- Support Vector Machines\n",
    "- Decision Trees\n",
    "- Boosted Trees\n",
    "- Random Forest\n",
    "- Neural Networks\n",
    "- Nearest Neighbor\n",
    "\n",
    "__For example :<br>\n",
    "Which of the following is/are classification problem(s)?__\n",
    "\n",
    "- Predicting the gender of a person by his/her handwriting style<br>\n",
    "- Predicting house price based on area<br>\n",
    "- Predicting whether monsoon will be normal next year<br>\n",
    "- Predict the number of copies a music album will be sold next month<br>\n",
    "\n",
    "_Solution :_ Predicting the gender of a person and  Predicting whether monsoon will be normal next year. The other two are regression.\n",
    "\n",
    "Supervised learning is also called predictive modeling or predictive analytics, because you build a model that is capable of making predictions.\n",
    "\n",
    "Some examples of predictive modeling are classification and regression. Classification identifies which category an item belongs to (e.g., whether a transaction is fraud or not fraud), based on labeled examples of known items (e.g., transactions known to be fraud or not). Logistic regression predicts a probability (e.g., the probability of fraud). Linear regression predicts a numeric value (e.g., the amount of fraud).\n",
    "\n",
    "![image.png](image/Logistic-Linear.png)\n",
    "\n",
    "### Classification and Regression Example\n",
    "Classification and regression take a set of data with known labels and predetermined features and learns how to label new records based on that information. Features are the \"if questions\" that you ask. The label is the answer to those questions.\n",
    "\n",
    "![image.png](image/duck.png)\n",
    "\n",
    "#### Regression Example\n",
    "\n",
    "Let's go through an example of car insurance fraud:\n",
    "\n",
    "- What are we trying to predict?\n",
    "\n",
    "        This is the label: the amount of fraud\n",
    "- What are the \"if questions\" or properties that you can use to predict?\n",
    "\n",
    "        These are the features: to build a classifier model, you extract the features of interest that most contribute to the classification.        \n",
    "        In this simple example, we will use the claimed amount.\n",
    "        \n",
    "Linear regression models the relationship between the Y \"Label\" and the X \"Feature,\" in this case the relationship between the amount of fraud and the claimed amount. The coefficient measures the impact of the feature, the claimed amount, and on the label, the fraud amount.\n",
    "\n",
    "Multiple linear regression models the relationship between two or more \"Features\" and a response \"Label.\" For example, if we wanted to model the relationship between the amount of fraud and the age of the claimant, the claimed amount, and the severity of the accident, the multiple linear regression function would look like this:\n",
    "\n",
    "Yi = β0 + β1X1 + β2X2 + · · · + βp Xp + Ɛ\n",
    "\n",
    "Amount Fraud = intercept + (coefficient1 age) + (coefficient2 claimed Amount) + (coefficient3 * severity) + error.\n",
    "\n",
    "\n",
    "The coefficients measure the impact on the fraud amount of each of the features.\n",
    "\n",
    "Some examples of linear regression include:\n",
    "\n",
    "- Given historical car insurance fraudulent claims and features of the claims, such as age of the claimant, claimed amount, and severity of the accident, predict the amount of fraud.\n",
    "- Given historical real estate sales prices and features of houses (square feet, number of bedrooms, location, etc.), predict a house's price.\n",
    "- Given historical neighborhood crime statistics, predict crime rate.\n",
    "\n",
    "\n",
    "#### Classification Example\n",
    "\n",
    "Let's go through an example of debit card fraud:\n",
    "\n",
    "- What are we trying to predict?\n",
    "\n",
    "        This is the label: probability of fraud\n",
    "    \n",
    "- What are the \"if questions\" or properties that you can use to make predictions?\n",
    "\n",
    "        Is the amount spent today > historical average?\n",
    "        Are there transactions in multiple countries today?\n",
    "        Are the number of transactions today > historical average?\n",
    "        Are the number of new merchant types today high compared to the last 3 months?\n",
    "        Are there multiple purchases today from merchants with a category code of risk?\n",
    "        Is there unusual signing activity today, compared to historically using pin?\n",
    "        Are there new state purchases compared to the last 3 months?\n",
    "        Are there foreign purchases today compared to the last 3 months?\n",
    "\n",
    "To build a classifier model, you extract the features of interest that most contribute to the classification.\n",
    "\n",
    "\n",
    "_Some examples of classification include:_\n",
    "\n",
    "    Given historical car insurance fraudulent claims and features of the claims, such as age of the claimant, claimed amount, and severity of the accident, predict the probability of fraud.\n",
    "    Given patient characteristics, predict the probability of congestive heart failure.\n",
    "    Credit card fraud detection (fraud, not fraud)\n",
    "    Credit card application (good credit, bad credit)\n",
    "    Email spam detection (spam, not spam)\n",
    "    Text sentiment analysis (happy, not happy)\n",
    "    Predicting patient risk (high risk patient, low risk patient)\n",
    "    Classifying a tumor (malignant, not malignant)\n",
    "    \n",
    "Liner regresstion\n",
    "\n",
    "    \tFind the releationship between depedent variable and independent variables. Using simple line.\n",
    "        This used to continuse.\n",
    "    \tLR solve regresstion progblem.\n",
    "    \tLR Response varaible is continus in nature.\n",
    "    \tIt help estimate the depedent variable when there is change in the indepdent varaible  \n",
    "\t\n",
    "Logistic Regresstion:\n",
    "\n",
    "    \tBut here depedent variable will be catorigcal. Example. Please find below Year of experience and got promated and not promated. Hence all the point lies between 0 and 1 .\n",
    "    \tSo we will not able to fit liner line in this case a RMS value will be huge.\n",
    "    \tY = mx + c is same { y will be catogrical variable }\n",
    "    \tHence what we will do is , we create I new function and plot.\n",
    "    \tLogistic is good for outlier.\n",
    "    \tLogistic Regresstion used to solve catorigcal problem.\n",
    "    \tLogistic Regresstion response variable is catorigcal.\n",
    "    \tWhiel Logistic regresstion help to caclulation the posbilites event taking place\n",
    "![image.png](image/Difference-Between-Linear-Regression-and-Logistic-Regression.jpg)\n",
    "\n",
    "![image.png](image/Logistic-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Math Behind Logistic Regression\n",
    "_To understand Logistic Regression, lets talk about the odds of success :_\n",
    "\n",
    "![image.png](image/MathFunction.png)\n",
    "\n",
    "So when we finally obtain the equation of the sigmoid function, we plot the sigmoid curve on the axis.\n",
    "\n",
    "Imagine your car has not been serviced from quite a few years and you want to find out if it’s going to breakdown in future or not. So this is a classification problem whether your car will break down or not. Lets look at the approach.\n",
    "\n",
    "If we plot the information along the X axis and Y axis. X is number of years since the last service was performed and Y axis is the probability of your car breaking down.\n",
    "\n",
    "![image.png](image/sigmoid.png)\n",
    "\n",
    "Imagine your car has not been serviced from quite a few years and you want to find out if it’s going to breakdown in future or not. So this is a classification problem whether your car will break down or not. Lets look at the approach.\n",
    "\n",
    "If we plot the information along the X axis and Y axis. X is number of years since the last service was performed and Y axis is the probability of your car breaking down.\n",
    "\n",
    "![image.png](image/Thershold.png)\n",
    "\n",
    "\n",
    "_Let’s understand it further using an example:_\n",
    "\n",
    "We are provided a sample of 1000 customers. We need to predict the probability whether a customer will buy (y) a particular magazine or not. As you can see, we’ve a categorical outcome variable, we’ll use logistic regression.\n",
    "\n",
    "To start with logistic regression, I’ll first write the simple linear regression equation with dependent variable enclosed in a link function:\n",
    "\n",
    "                         g(y) = βo + β(Age)         ---- (a)\n",
    "Note: For ease of understanding, I’ve considered ‘Age’ as independent variable.\n",
    "\n",
    "In logistic regression, we are only concerned about the probability of outcome dependent variable ( success or failure). As described above, g() is the link function. This function is established using two things: Probability of Success(p) and Probability of Failure(1-p). p should meet following criteria:\n",
    "\n",
    "1) It must always be positive (since p >= 0)<br>\n",
    "2) It must always be less than equals to 1 (since p <= 1)<br>\n",
    "\n",
    "__Since probability must always be positive, we’ll put the linear equation in exponential form. For any value of slope and dependent variable, exponent of this equation will never be negative.__\n",
    "\n",
    "                        p = exp(βo + β(Age)) = e^(βo + β(Age))    ------- (b)\n",
    "                        \n",
    "To make the probability less than 1, we must divide p by a number greater than p. This can simply be done by:\n",
    "\n",
    "                   p  =  exp(βo + β(Age)) / exp(βo + β(Age)) + 1   =   e^(βo + β(Age)) / e^(βo + β(Age)) + 1    ----- (c)\n",
    "                   \n",
    "Using (a), (b) and (c), we can redefine the probability as:\n",
    "\n",
    "                       p = e^y/ 1 + e^y           --- (d)\n",
    "where p is the probability of success. This (d) is the Logit Function\n",
    "\n",
    "If p is the probability of success, 1-p will be the probability of failure which can be written as\n",
    "\n",
    "                        q = 1 - p = 1 - (e^y/ 1 + e^y)    --- (e)\n",
    "                        \n",
    "where q is the probability of failure On dividing, (d) / (e), we get,\n",
    "\n",
    "sigmoid function  = p/(1-p) = e^y\n",
    "\n",
    "After taking log on both side, we get,  = log[p/(1-p)] = y \n",
    "\n",
    "log(p/1-p) is the link function. Logarithmic transformation on the outcome variable allows us to model a non-linear association in a linear way.\n",
    "\n",
    "After substituting value of y, we’ll get:\n",
    "\n",
    "                            log[p/(1-p)] = βo + β(Age)\n",
    "                            \n",
    "This is the equation used in Logistic Regression. Here (p/1-p) is the odd ratio. Whenever the log of odd ratio is found to be positive, the probability of success is always more than 50%. A typical logistic model plot show above. You can see probability never goes below 0 and above 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Logistic Regression ?\n",
    "\n",
    "Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary / categorical outcome, we use dummy variables. You can also think of logistic regression as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as dependent variable. In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function\n",
    "\n",
    "### Types of Logistic Regression \n",
    "\n",
    "- Binary Logistic Regression ( Two class logistic Regresstion )\n",
    "        The categorical response has only two 2 possible outcomes. Example: Spam or Not\n",
    "\n",
    "- Multinomial Logistic Regression\n",
    "        Three or more categories without ordering. Example: Predicting which food is preferred more (Veg, Non-Veg, Vegan)\n",
    "        \n",
    "- Ordinal Logistic Regression\n",
    "        Three or more categories with ordering. Example: Movie rating from 1 to 5\n",
    "        \n",
    "- One-vs-All Classification Using Logistic Regression\n",
    "        First of all, let me briefly explain the idea behind one-vs-all classification. we have a classification problem and there are N distinct classes. In this case, we’ll have to train a multi-class classifier instead of a binary one.\n",
    "        \n",
    "![image](image/one-vs-All.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why logistic regression not linear  .... ?\n",
    "\n",
    "When the response variable has only 2 possible values, it is desirable to have a model that predicts the value either as 0 or 1 or as a probability score that ranges between 0 and 1.\n",
    "\n",
    "Linear regression does not have this capability. Because, If you use linear regression to model a binary response variable, the resulting model may not restrict the predicted Y values within 0 and 1.\n",
    "\n",
    "This is where logistic regression comes into play. In logistic regression, you get a probability score that reflects the probability of the occurence of the event.\n",
    "\n",
    "An event in this case is each row of the training dataset. It could be something like classifying if a given email is spam, or mass of cell is malignant or a user will buy a product and so on.\n",
    "\n",
    "![image](image/Logistic-Linear_2.png)\n",
    "\n",
    "Linear Regression model probability : -∞  to +∞ <br>\n",
    "Probability of outcome lie between : 0< p< 1\n",
    "\n",
    "__Linear Regression has a considerable effects on OUTLIERS__ but to avoid this probelm, log-odds function or logit function is used.\n",
    "\n",
    "Logistic Regression will take care on __OUTLIERS__\n",
    "\n",
    "\n",
    "\n",
    "### Logit Function\n",
    "\n",
    "The odds for an event is the (probability of an event occuring) / (probability of event not occuring):\n",
    "\n",
    "\n",
    "For Linear regression: continuous response is modeled as a linear combination of the features: y = β0 + β1x\n",
    "For Logistic regression: log-odds of a categorical response being \"true\" (1) is modeled as a linear combination of the features:\n",
    "\n",
    "![image.png](image/Logistic-odds.png)\n",
    "\n",
    "_Figure.1_ This is called the logit function. On solving for probability (p) you will get:<br>\n",
    "_Figure.2_ Showing linear model and logistic model:\n",
    "\n",
    "_What is odd ?_ The odds signifies the ratio of probability of success to probability of failure.\n",
    "\n",
    "__Example: India and Pakistan__\n",
    "\n",
    "India winning a match is termed as successful event. While india losing a match is termed as Failure.\n",
    "\n",
    "![image.png](image/Logit1.png)\n",
    "\n",
    "In other words:\n",
    "\n",
    "- Logistic regression outputs the __probabilities of a specific class__.\n",
    "- Those probabilities can be converted into __class predictions__.\n",
    "\n",
    "\n",
    "The logistic function has some nice properties:\n",
    "\n",
    "- Takes on an __\"s\"__ shape\n",
    "- Output is bounded by __0 and 1__<br/>\n",
    "\n",
    "\n",
    "We have covered how this works for binary classification problems (two response classes). But what about __multi-class classification problems__ (more than two response classes)?\n",
    "\n",
    "- Most common solution for classification models is __\"one-vs-all\"__ (also known as __\"one-vs-rest\"__): decompose the problem into multiple binary classification problems.\n",
    "- __Multinomial logistic regression__ can solve this as a single problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Logistic Regression\n",
    "\n",
    "__Pros__\n",
    "\n",
    "- simple and efficient \n",
    "- Low variance\n",
    "- it Provide probability score for observation\n",
    "\n",
    "__ Cons__\n",
    "\n",
    "-Doesn't handle large number of categorical feature/variables well.\n",
    "- it requires transformation of non-linear features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples \n",
    "_Training a Simple Binary Classifier Using Logistic Regression_\n",
    "\n",
    "__Problem & Dataset__\n",
    "Our objective in this problem is to estimate an applicant’s probability of admission into a university based on his/her results on two exams.Our dataset contains some historical data from previous applicants, \n",
    "\n",
    "Please refer if want to understand backend of algo.\n",
    "https://utkuufuk.com/categories/Machine-Learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods do we use to best fit the data in Logistic Regression\n",
    "\n",
    "    Maximum Likelihood  (Logistic regression uses maximum likely hood estimate for training a logistic regression.)<br>\n",
    "    Least Square Error\n",
    "    AUC-ROC\n",
    "    Accuracy\n",
    "    Logloss\n",
    "    One of the very good methods to analyze the performance of Logistic Regression is AIC,which is similar to R-Squared in Linear Regression. We prefer a model with minimum AIC value. We select the best model in logistic regression which can least AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Logistic Regression\n",
    "Lets talk about some practical uses of logistic regression\n",
    "\n",
    "__Weather Prediction :__ It determines what kind of weather can be expected.Is it going to rain or not, or it would be sunny or not, or it would be snowy or not. But if we want to determine what would be the temperature tomorrow, we use linear regression.<br>\n",
    "__Image Categorization :__ Identifies different components that are present in the image and helps categorize them.<br>\n",
    "__Healthcare (TRISS) :__ Determine the possibility of patient’s survival , taking Age, ISS(Injury Severity Score) , RTS (Revised Trauma Score) into consideration.<br>\n",
    "\n",
    "\n",
    "Logistic Regression was used in __biological sciences__ in early twentieth century. It was then used in many social science applications. For instance,\n",
    "- The Trauma and Injury Severity Score (TRISS), which is widely used to __predict mortality in injured patients__, was originally developed by Boyd et al. using logistic regression.<br/> \n",
    "- Many other medical scales used to __assess severity__ of a patient have been developed using logistic regression.<br/>\n",
    "- Logistic regression may be used to __predict the risk of developing a given disease__ (e.g. diabetes; coronary heart disease), based on observed characteristics of the patient (age, sex, body mass index, results of various blood tests, etc.).<br/>\n",
    "\n",
    "Now a days, Logistic Regression have the following applications \n",
    "1. Image segementation and  categorization\n",
    "2. Geographic image processing\n",
    "3. Handwriting recognition\n",
    "4. Detection of  myocardinal infarction\n",
    "5. Predict whether a person is depressed or not based on a bag of words from corpus. \n",
    "\n",
    "\n",
    "The reason why logistic regression is widely used despite of the state of the art of deep neural network is that logistic regression is very __efficient__ and does __not__ require too much __computational resources__, which makes it __affordable__ to run on production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
